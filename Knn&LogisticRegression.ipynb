{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de0ac1c0-54d2-4180-9c81-0b045b48aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "132c1945-afb1-4d4a-b7de-2a44656be160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USMER</th>\n",
       "      <th>MEDICAL_UNIT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATIENT_TYPE</th>\n",
       "      <th>DATE_DIED</th>\n",
       "      <th>INTUBED</th>\n",
       "      <th>PNEUMONIA</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PREGNANT</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>...</th>\n",
       "      <th>ASTHMA</th>\n",
       "      <th>INMSUPR</th>\n",
       "      <th>HIPERTENSION</th>\n",
       "      <th>OTHER_DISEASE</th>\n",
       "      <th>CARDIOVASCULAR</th>\n",
       "      <th>OBESITY</th>\n",
       "      <th>RENAL_CHRONIC</th>\n",
       "      <th>TOBACCO</th>\n",
       "      <th>CLASIFFICATION_FINAL</th>\n",
       "      <th>ICU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>03/05/2020</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>03/06/2020</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>09/06/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12/06/2020</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21/06/2020</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  PNEUMONIA  \\\n",
       "0      2             1    1             1  03/05/2020       97          1   \n",
       "1      2             1    2             1  03/06/2020       97          1   \n",
       "2      2             1    2             2  09/06/2020        1          2   \n",
       "3      2             1    1             1  12/06/2020       97          2   \n",
       "4      2             1    2             1  21/06/2020       97          2   \n",
       "\n",
       "   AGE  PREGNANT  DIABETES  ...  ASTHMA  INMSUPR  HIPERTENSION  OTHER_DISEASE  \\\n",
       "0   65         2         2  ...       2        2             1              2   \n",
       "1   72        97         2  ...       2        2             1              2   \n",
       "2   55        97         1  ...       2        2             2              2   \n",
       "3   53         2         2  ...       2        2             2              2   \n",
       "4   68        97         1  ...       2        2             1              2   \n",
       "\n",
       "   CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  TOBACCO  CLASIFFICATION_FINAL  ICU  \n",
       "0               2        2              2        2                     3   97  \n",
       "1               2        1              1        2                     5   97  \n",
       "2               2        2              2        2                     3    2  \n",
       "3               2        2              2        2                     7   97  \n",
       "4               2        2              2        2                     3   97  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'Covid Data.csv'\n",
    "covid = pd.read_csv(\"Covid Data.csv\", low_memory = False)\n",
    "covid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17450438-db16-4025-96b3-1e4390db6c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 21)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd36e54-261d-4cc5-8c02-572ad9db73a6",
   "metadata": {},
   "source": [
    "# Encodage et suppression des valeurs manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e7b103e-33ca-4f1a-bc2f-cccd8fd247b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= [\n",
    "    \"SEX\", \"USMER\", \"PATIENT_TYPE\", \"PNEUMONIA\", \"DIABETES\", \n",
    "    \"COPD\", \"ASTHMA\", \"INMSUPR\", \"HIPERTENSION\", \"OTHER_DISEASE\",\n",
    "    \"CARDIOVASCULAR\", \"OBESITY\", \"RENAL_CHRONIC\", \"TOBACCO\"\n",
    "]\n",
    "covid = covid.loc[covid.CLASIFFICATION_FINAL < 4]\n",
    "for column in columns:\n",
    "    covid = covid.loc[(covid[column] == 1) | (covid[column] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d17b61c-0db2-4581-bf76-27d75113617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"SEX\", \"USMER\", \"PNEUMONIA\", \"DIABETES\", \"COPD\", \n",
    "    \"ASTHMA\", \"INMSUPR\", \"HIPERTENSION\", \"OTHER_DISEASE\", \n",
    "    \"CARDIOVASCULAR\", \"OBESITY\", \"RENAL_CHRONIC\", \"TOBACCO\", \n",
    "    \"PREGNANT\", \"INTUBED\", \"ICU\"\n",
    "]\n",
    "for column in columns:\n",
    "    covid[column] = covid[column].apply(lambda x: x if x == 1 else 0)\n",
    "covid[\"PATIENT_TYPE\"] = covid[\"PATIENT_TYPE\"].apply(lambda x: 0 if x == 1 else 1)\n",
    "covid[\"DATE_DIED\"] = covid[\"DATE_DIED\"].apply(lambda x: 0 if x == \"9999-99-99\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "045e889e-a8a8-4f0c-99a1-4599f9a9f837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388878, 21)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169dcd0-8c4b-40f2-bc0e-b712919dcc0d",
   "metadata": {},
   "source": [
    "# feature engeniring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74e1c7d8-4653-4490-add3-0903d87e47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "covid['AT_RISK'] = covid['DATE_DIED'] + covid['INTUBED'] + covid['ICU']\n",
    "covid.AT_RISK = covid.AT_RISK.apply(lambda x: 1 if x > 0 else 0) \n",
    "\n",
    "# Drop a few columns which are intuitively not longer useful\n",
    "covid.drop(columns = ['CLASIFFICATION_FINAL', 'INTUBED', 'ICU', 'DATE_DIED'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44c3cb8d-c3e1-4540-93ff-e9ec15251d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 388878 entries, 0 to 1047937\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count   Dtype\n",
      "---  ------          --------------   -----\n",
      " 0   USMER           388878 non-null  int64\n",
      " 1   MEDICAL_UNIT    388878 non-null  int64\n",
      " 2   SEX             388878 non-null  int64\n",
      " 3   PATIENT_TYPE    388878 non-null  int64\n",
      " 4   PNEUMONIA       388878 non-null  int64\n",
      " 5   AGE             388878 non-null  int64\n",
      " 6   PREGNANT        388878 non-null  int64\n",
      " 7   DIABETES        388878 non-null  int64\n",
      " 8   COPD            388878 non-null  int64\n",
      " 9   ASTHMA          388878 non-null  int64\n",
      " 10  INMSUPR         388878 non-null  int64\n",
      " 11  HIPERTENSION    388878 non-null  int64\n",
      " 12  OTHER_DISEASE   388878 non-null  int64\n",
      " 13  CARDIOVASCULAR  388878 non-null  int64\n",
      " 14  OBESITY         388878 non-null  int64\n",
      " 15  RENAL_CHRONIC   388878 non-null  int64\n",
      " 16  TOBACCO         388878 non-null  int64\n",
      " 17  AT_RISK         388878 non-null  int64\n",
      "dtypes: int64(18)\n",
      "memory usage: 56.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(covid.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49770b89-bd71-4008-bffd-42976ebf5a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT_RISK\n",
       "0    328899\n",
       "1     59979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid['AT_RISK'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f407f860-bf9a-4b9e-ab51-7c0ba56f1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(covid, test_size=0.1, shuffle=True)\n",
    "validation, test = train_test_split(validation, test_size=0.5, shuffle=True)\n",
    "\n",
    "validation_y = validation.AT_RISK.to_numpy()\n",
    "validation_x = validation.drop(columns = ['AT_RISK']).to_numpy()\n",
    "\n",
    "test_y = test.AT_RISK.to_numpy()\n",
    "test_x = test.drop(columns = ['AT_RISK']).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f2813-bdd2-4a6c-ac60-ec920560811d",
   "metadata": {},
   "source": [
    "## Calculate results\n",
    "### function that returns F-measure (F1-score) for given data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3aa14b7-b1c2-4abe-a79d-2235713a13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'evaluation\n",
    "def get_f_measure(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the F-measure (F1-score) based on predictions and true labels.\n",
    "\n",
    "    Parameters:\n",
    "    - predictions: numpy array of predicted labels (binary: 0 or 1).\n",
    "    - labels: numpy array of true labels (binary: 0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    - f_measure: The F1-score, a harmonic mean of precision and recall.\n",
    "    \"\"\"\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positive = np.sum((predictions == 1) & (labels == 1))\n",
    "    false_positive = np.sum((predictions == 1) & (labels == 0))\n",
    "    false_negative = np.sum((predictions == 0) & (labels == 1))\n",
    "\n",
    "    # Avoid division by zero with small epsilon\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = true_positive / (true_positive + false_positive + epsilon)\n",
    "    recall = true_positive / (true_positive + false_negative + epsilon)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f_measure = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "\n",
    "    return f_measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36ce83-220d-458b-a6a0-b616562d2894",
   "metadata": {},
   "source": [
    "### Umdersamplinfg the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63e0f57a-b9da-40df-bbf0-4f40a42f1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "atrisk = train[train.AT_RISK==1][:2000]\n",
    "nonrisk = train[train.AT_RISK==0][:2000]\n",
    "part_train = pd.concat([nonrisk, atrisk])\n",
    "train_y = part_train.AT_RISK.to_numpy()\n",
    "train_x = part_train.drop(columns = ['AT_RISK']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3408b908-8ddd-49c9-a9e1-1296aba194e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32942218-3b77-4f19-9313-6411e825d2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 17)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497a8d6-1a8b-480d-bca0-695657ca96d2",
   "metadata": {},
   "source": [
    "## Implementation de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cc5edbc-2f8d-4eea-827f-ea94c2f578f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# # Initialiser le classifieur KNN avec 5 voisins\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# # Entraîner le modèle sur l'ensemble d'entraînement\n",
    "# knn_model.fit(train_x, train_y)\n",
    "\n",
    "# # Prédire sur l'ensemble de validation\n",
    "# validation_predictions = knn_model.predict(validation_x)\n",
    "\n",
    "# # Évaluer les performances sur l'ensemble de validation\n",
    "# print(\"Rapport de classification (validation) :\")\n",
    "# print(classification_report(validation_y, validation_predictions))\n",
    "# print(\"Précision globale (validation) :\", accuracy_score(validation_y, validation_predictions))\n",
    "\n",
    "# # Prédire sur l'ensemble de test\n",
    "# test_predictions = knn_model.predict(test_x)\n",
    "\n",
    "# # Évaluer les performances sur l'ensemble de test\n",
    "# print(\"Rapport de classification (test) :\")\n",
    "# print(classification_report(test_y, test_predictions))\n",
    "# print(\"Précision globale (test) :\", accuracy_score(test_y, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415a9ff-dc9f-4f8b-8c09-5700bd834ca3",
   "metadata": {},
   "source": [
    "### Implementation 2 de KNN avec une fonction pour savoir la meilleure valeur de K possible pour l'algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df6e5dab-c75f-4cd1-9dd8-8d8e19ef59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Standardisation des données\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Ajuster le scaler sur les données d'entraînement et transformer\n",
    "# train_x = scaler.fit_transform(train_x)\n",
    "\n",
    "# # Transformer les ensembles de validation et de test\n",
    "# validation_x = scaler.transform(validation_x)\n",
    "# test_x = scaler.transform(test_x)\n",
    "\n",
    "# # Fonction pour tester différentes valeurs de k\n",
    "# def find_best_k(train_x, train_y, validation_x, validation_y, k_values):\n",
    "#     best_k = None\n",
    "#     best_accuracy = 0\n",
    "#     accuracies = []\n",
    "\n",
    "#     print(\"Test des différentes valeurs de k :\")\n",
    "#     for k in k_values:\n",
    "#         # Initialiser le modèle KNN avec k voisins\n",
    "#         knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "#         # Entraîner le modèle\n",
    "#         knn_model.fit(train_x, train_y)\n",
    "        \n",
    "#         # Prédire sur l'ensemble de validation\n",
    "#         validation_predictions = knn_model.predict(validation_x)\n",
    "        \n",
    "#         # Calculer la précision\n",
    "#         accuracy = accuracy_score(validation_y, validation_predictions)\n",
    "#         accuracies.append(accuracy)\n",
    "\n",
    "#         print(f\"k = {k}, Précision = {accuracy:.4f}\")\n",
    "\n",
    "#         # Mettre à jour la meilleure valeur de k si nécessaire\n",
    "#         if accuracy > best_accuracy:\n",
    "#             best_accuracy = accuracy\n",
    "#             best_k = k\n",
    "\n",
    "#     return best_k, best_accuracy, accuracies\n",
    "\n",
    "# # Liste des valeurs de k à tester\n",
    "# k_values = range(1, 21)  # Par exemple, tester de 1 à 20 voisins\n",
    "\n",
    "# # Trouver la meilleure valeur de k\n",
    "# best_k, best_accuracy, accuracies = find_best_k(train_x, train_y, validation_x, validation_y, k_values)\n",
    "\n",
    "# print(f\"\\nLa meilleure valeur de k est {best_k} avec une précision de {best_accuracy:.4f}.\")\n",
    "\n",
    "# # Entraîner le modèle KNN avec la meilleure valeur de k et évaluer sur l'ensemble de test\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "# knn_model.fit(train_x, train_y)\n",
    "\n",
    "# # Prédictions sur l'ensemble de test\n",
    "# test_predictions = knn_model.predict(test_x)\n",
    "\n",
    "# # Évaluation des performances\n",
    "# print(\"\\nRapport de classification (test) :\")\n",
    "# print(classification_report(test_y, test_predictions))\n",
    "# print(\"Précision globale (test) :\", accuracy_score(test_y, test_predictions))\n",
    "# print(\"F1-score (test) :\", f1_score(test_y, test_predictions))\n",
    "\n",
    "# # Tracer les précisions en fonction de k (optionnel)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(k_values, accuracies, marker='o', linestyle='-', color='b')\n",
    "# plt.title(\"Précision sur l'ensemble de validation en fonction de k\")\n",
    "# plt.xlabel(\"Nombre de voisins (k)\")\n",
    "# plt.ylabel(\"Précision\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c18784-4565-4116-b375-72df8e0ca8bf",
   "metadata": {},
   "source": [
    "## Implementation  de KNN avec GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f28979ad-bd71-462e-bbf4-bbb1f65a2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Meilleure valeur de k : 11\n",
      "Précision moyenne sur la validation (cross-validation) : 0.8820\n",
      "Matrice de confusion\n",
      " [[13624  2871]\n",
      " [  209  2740]]\n",
      "\n",
      "Rapport de classification (test) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90     16495\n",
      "           1       0.49      0.93      0.64      2949\n",
      "\n",
      "    accuracy                           0.84     19444\n",
      "   macro avg       0.74      0.88      0.77     19444\n",
      "weighted avg       0.91      0.84      0.86     19444\n",
      "\n",
      "Précision globale (test) : 0.8415963793458137\n",
      "F1-score (test) : 0.6401869158878505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajuster le scaler sur les données d'entraînement et transformer\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "\n",
    "# Transformer les ensembles de validation et de test\n",
    "validation_x = scaler.transform(validation_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# Définir le modèle KNN\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Définir les paramètres à tester (ici les valeurs de k)\n",
    "param_grid = {'n_neighbors': range(1, 21)}  # Tester les k de 1 à 20\n",
    "\n",
    "# Initialiser GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Effectuer la recherche sur l'ensemble d'entraînement\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Meilleure valeur de k et meilleure précision\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Meilleure valeur de k : {best_k}\")\n",
    "print(f\"Précision moyenne sur la validation (cross-validation) : {best_accuracy:.4f}\")\n",
    "\n",
    "# Évaluer le modèle final sur l'ensemble de test\n",
    "final_model = grid_search.best_estimator_\n",
    "test_predictions = final_model.predict(test_x)\n",
    "\n",
    "print(\"Matrice de confusion\\n\", confusion_matrix(test_y, test_predictions))\n",
    "\n",
    "print(\"\\nRapport de classification (test) :\")\n",
    "print(classification_report(test_y, test_predictions))\n",
    "print(\"Précision globale (test) :\", accuracy_score(test_y, test_predictions))\n",
    "print(\"F1-score (test) :\", f1_score(test_y, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb0fa6-df6a-446f-af15-fd5c73b38f39",
   "metadata": {},
   "source": [
    "## Implementation Regression Logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "260ece50-92f1-4e37-8507-6173e78611e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification (test) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91     16445\n",
      "           1       0.53      0.91      0.67      2999\n",
      "\n",
      "    accuracy                           0.86     19444\n",
      "   macro avg       0.75      0.88      0.79     19444\n",
      "weighted avg       0.91      0.86      0.87     19444\n",
      "\n",
      "Précision globale (test) : 0.8602653774943427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "validation_x = scaler.transform(validation_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "# Initialisation du modèle\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Entraînement du modèle\n",
    "logistic_model.fit(train_x, train_y)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "test_predictions = logistic_model.predict(test_x)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Rapport de classification (test) :\")\n",
    "print(classification_report(test_y, test_predictions))\n",
    "\n",
    "print(\"Précision globale (test) :\", accuracy_score(test_y, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2861a70-6456-48db-b941-2bd90aa2846c",
   "metadata": {},
   "source": [
    "## Implementation de la regression lineaireavec gridSearchCV pour justifier le choix des hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b6de52d-5e0a-4740-b774-a9da6d24ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : {'logisticregression__C': 0.1, 'logisticregression__max_iter': 100, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "Matrice de confusion\n",
      " [[14068  2427]\n",
      " [  244  2705]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91     16495\n",
      "           1       0.53      0.92      0.67      2949\n",
      "\n",
      "    accuracy                           0.86     19444\n",
      "   macro avg       0.76      0.89      0.79     19444\n",
      "weighted avg       0.91      0.86      0.88     19444\n",
      "\n",
      "Précision globale : 0.8626311458547624\n",
      "F1-score (test) : 0.6694716000494988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "450 fits failed out of a total of 900.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\NEW\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.879       nan     nan 0.87925 0.8825  0.882   0.882   0.882       nan\n",
      "     nan     nan     nan 0.879       nan     nan 0.87925 0.8825  0.882\n",
      " 0.882   0.882       nan     nan     nan     nan 0.879       nan     nan\n",
      " 0.87925 0.8825  0.882   0.882   0.882       nan     nan     nan     nan\n",
      " 0.883       nan     nan 0.88225 0.883   0.883   0.88275 0.883       nan\n",
      "     nan     nan     nan 0.883       nan     nan 0.88225 0.883   0.883\n",
      " 0.88275 0.883       nan     nan     nan     nan 0.883       nan     nan\n",
      " 0.88225 0.883   0.883   0.88275 0.883       nan     nan     nan     nan\n",
      " 0.882       nan     nan 0.882   0.882   0.882   0.882   0.882       nan\n",
      "     nan     nan     nan 0.882       nan     nan 0.882   0.882   0.882\n",
      " 0.882   0.882       nan     nan     nan     nan 0.88225     nan     nan\n",
      " 0.882   0.882   0.882   0.882   0.882       nan     nan     nan     nan\n",
      " 0.882       nan     nan 0.882   0.882   0.882   0.882   0.882       nan\n",
      "     nan     nan     nan 0.882       nan     nan 0.882   0.882   0.882\n",
      " 0.882   0.882       nan     nan     nan     nan 0.882       nan     nan\n",
      " 0.882   0.882   0.882   0.882   0.882       nan     nan     nan     nan\n",
      " 0.882       nan     nan 0.882   0.882   0.882   0.882   0.882       nan\n",
      "     nan     nan     nan 0.882       nan     nan 0.882   0.882   0.882\n",
      " 0.882   0.882       nan     nan     nan     nan 0.882       nan     nan\n",
      " 0.882   0.882   0.882   0.882   0.882       nan     nan     nan     nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Créez un pipeline avec standardisation et régression logistique\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Définissez la grille de recherche des paramètres\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],  # Valeurs possibles de C\n",
    "    'logisticregression__solver': ['liblinear', 'newton-cg', 'lbfgs', 'saga'],  # Algorithmes d'optimisation\n",
    "    'logisticregression__penalty': ['l1', 'l2', 'elasticnet'],  # Types de régularisation\n",
    "    'logisticregression__max_iter': [100, 200, 300]  # Nombre maximal d'itérations\n",
    "}\n",
    "\n",
    "# Initialiser GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Entraînement avec les données d'entraînement\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "\n",
    "# Affichage du meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Évaluation du modèle sur le jeu de test\n",
    "test_predictions = best_model.predict(test_x)\n",
    "\n",
    "print(\"Matrice de confusion\\n\", confusion_matrix(test_y, test_predictions))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(test_y, test_predictions))\n",
    "\n",
    "# Précision globale\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Précision globale :\", accuracy_score(test_y, test_predictions))\n",
    "print(\"F1-score (test) :\", f1_score(test_y, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3908e6b-c675-4a97-8513-75c737dee144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : {'logisticregression__C': 0.1, 'logisticregression__max_iter': 100, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "Matrice de confusion\n",
      " [[14068  2427]\n",
      " [  244  2705]]\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91     16495\n",
      "           1       0.53      0.92      0.67      2949\n",
      "\n",
      "    accuracy                           0.86     19444\n",
      "   macro avg       0.76      0.89      0.79     19444\n",
      "weighted avg       0.91      0.86      0.88     19444\n",
      "\n",
      "Précision globale : 0.8626311458547624\n",
      "F1-score (test) : 0.6694716000494988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Créez un pipeline avec standardisation et régression logistique\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Définissez la grille de recherche des paramètres avec des combinaisons compatibles\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],  # Valeurs possibles de C\n",
    "    'logisticregression__solver': ['liblinear', 'saga'],  # Choisir des solveurs compatibles\n",
    "    'logisticregression__penalty': ['l1', 'l2'],  # Choisir les pénalités compatibles\n",
    "    'logisticregression__max_iter': [100, 200, 300]  # Nombre maximal d'itérations\n",
    "}\n",
    "\n",
    "# Initialiser GridSearchCV avec `error_score='raise'` pour détecter les erreurs\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', error_score='raise')\n",
    "\n",
    "# Entraînement avec les données d'entraînement\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "\n",
    "# Affichage du meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Évaluation du modèle sur le jeu de test\n",
    "test_predictions = best_model.predict(test_x)\n",
    "\n",
    "print(\"Matrice de confusion\\n\", confusion_matrix(test_y, test_predictions))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(test_y, test_predictions))\n",
    "\n",
    "# Précision globale\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Précision globale :\", accuracy_score(test_y, test_predictions))\n",
    "print(\"F1-score (test) :\", f1_score(test_y, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114465eb-a33c-4a95-a68f-3a0f90672146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc66c1-166c-41ae-bf5b-aee6586f40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
